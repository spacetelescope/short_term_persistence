{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to study short term persistence from multiple exposures in a single visit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import glob, os, shutil, pickle, bz2, gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sigmaclip\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import gammaincc, gamma\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import histogram\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "from crds import bestrefs\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user/gennaro/Functional_work/WFC3_persistence/py_progs/short_term_persistence/Pixel_based'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The project dir \n",
    "pdir = '/user/gennaro/Functional_work/WFC3_persistence/py_progs/short_term_persistence/'\n",
    "\n",
    "#The mosaic dir\n",
    "mdir = pdir+'/Mosaic_hi_res_folder/'\n",
    "\n",
    "#The dir to save/load the Persistence curves dataframes\n",
    "sdir = pdir+'/PD_dataframes_dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion factor from days to seconds\n",
    "daytosec = 24.*3600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Single and double exponential models to be fitted to the data\n",
    "\n",
    "def decay1(t,a1,t1):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1\n",
    "\n",
    "def intdec1(t,a1,t1):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td)\n",
    "    \n",
    "def decay2(t,a1,t1,a2,t2):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    e2 = a2*np.exp(-t/t2)\n",
    "    return e1+e2\n",
    "\n",
    "def intdec2(t,a1,t1,a2,t2):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k1,k2  = -a1*t1, - a2*t2\n",
    "    \n",
    "    return k1*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) + k2*(np.exp(-tu/t2)-np.exp(-td/t2))/(tu-td)\n",
    "\n",
    "#Single exponential models plus a constant\n",
    "\n",
    "def intdec1_plusconst(t,a1,t1,q):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) +q\n",
    "\n",
    "def dec1_plusconst(t,a1,t1,q):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1+q\n",
    "\n",
    "\n",
    "#Shifted power law model\n",
    "\n",
    "def shpwl(t,t0,A,index):\n",
    "    return A * ((t+t0)/1000)**index\n",
    "\n",
    "def intshpwl(t,t0,A,index):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "\n",
    "    if (index == -1.):\n",
    "        return A*np.log( (tu+t0)/(td+t0) )\n",
    "    else:\n",
    "        return A/(1+index) * ( ((tu+t0)/1000)**(1+index) - ((td+t0)/1000)**(1+index) )/(tu-td)\n",
    "    \n",
    "    \n",
    "#Schechter like model\n",
    "\n",
    "def schechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "    return phi*(x**alpha)*np.exp(-x)\n",
    "\n",
    "def intschechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "\n",
    "    tu = x[1:]\n",
    "    td = x[:-1]\n",
    "\n",
    "    g1 = gammaincc(alpha+1,td)\n",
    "    g2 = gammaincc(alpha+1,tu)\n",
    "    \n",
    "    diff = gamma(alpha+1)*(g1-g2)\n",
    "    \n",
    "    return phi*diff\n",
    "\n",
    "\n",
    "#Geometric median calculation function\n",
    "\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "\n",
    "def geometric_median(X, eps=1e-5):\n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1, D\n",
    "\n",
    "        y = y1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes the vsflts list, the current flt that is being used as stimulus\n",
    "# and looks for all the pixels with valid stimulus values AND that have valid ramps (i.e. no source, only sky)\n",
    "# in the following exposures AND that where not stimulated more than prior-stim-factor (psf)% of the current stimulus in \n",
    "# ANY past exposure up to a certain look back exposure (lb).\n",
    "# Mario: added the option of multiplying the stimulus by the Pixel Area Map\n",
    "\n",
    "def find_ramps(istim,flts,lev_u,lev_d,lb=None,PAM=None,psf=0.1):\n",
    "        \n",
    "    stimdata  = flts[istim,:,:]*(tendMJDs[istim]-tstrMJDs[istim])*daytosec\n",
    "    \n",
    "    if PAM is not None:\n",
    "        stimdata *= PAM\n",
    "    \n",
    "    istimgood = (stimdata > lev_d) & (stimdata < lev_u)  \n",
    "    print('Pixels with potentially right stimuli:',np.sum(istimgood) )\n",
    "\n",
    "    if lb is not None:\n",
    "        if (istim-lb)>0:\n",
    "            st = istim-lb\n",
    "        else:\n",
    "            st = 0\n",
    "    else:\n",
    "        st = 0\n",
    "    \n",
    "    for i in range(st,istim,1):\n",
    "        earlierdata = flts[i,:,:] * (tendMJDs[i]-tstrMJDs[i])*daytosec \n",
    "        if PAM is not None:\n",
    "            earlierdata *= PAM\n",
    "\n",
    "        if (imtyps[i] == 'EXT'):\n",
    "            istimgood = istimgood & (earlierdata < psf*stimdata) \n",
    "            \n",
    "    print('Pixels with really right stimuli:',np.sum(istimgood) )\n",
    "    \n",
    "    \n",
    "    icount    = np.zeros_like(stimdata,dtype=np.int_)\n",
    "    iprev     = istimgood\n",
    "    for i in range(istim+1,len(imtyps),1):\n",
    "    \n",
    "        persdata = flts[i,:,:] * (tendMJDs[i]-tstrMJDs[i])*daytosec\n",
    "        if PAM is not None:\n",
    "            persdata *= PAM\n",
    "    \n",
    "        if (imtyps[i] == 'EXT'):\n",
    "            pfinite = persdata[np.isfinite(persdata)]\n",
    "            msky = np.nanmean(sigmaclip(pfinite,1.75,1.75)[0])\n",
    "            ssky = np.nanstd(sigmaclip(pfinite,2.5,2.5)[0])\n",
    "            print('Mean',msky)\n",
    "            print('Stdv',ssky)\n",
    "            \n",
    "            iskycurr = (persdata <msky+3.*ssky) & (persdata >msky-2*ssky)   \n",
    "#            iskycurr = (persdata < (25*(tendMJDs[istim]-tstrMJDs[istim])*daytosec)) & (persdata >(5*(tendMJDs[istim]-tstrMJDs[istim])*daytosec) ) \n",
    "#            print(msky,ssky)\n",
    "        elif (imtyps[i] == 'DARK'):\n",
    "            iskycurr = np.ones_like(persdata,dtype=np.bool_)\n",
    "        else:\n",
    "            print('Wrong image type')\n",
    "            assert False\n",
    "        \n",
    "        igood = istimgood & iskycurr & iprev\n",
    "        iprev = igood\n",
    "        icount[igood] += 1\n",
    "\n",
    "        print('Pixels with ramps extending for at least',i-istim,' exposures:', igood.sum())\n",
    "        \n",
    "        if (np.sum(igood) == 0):\n",
    "            break\n",
    "                 \n",
    "    return icount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dedfine a function to get the sky value in the cureent flt pixel, but measured form the AD mosaic\n",
    "\n",
    "def getskyfrommosaic(wcsAD, wcsFLT, x, y, dxgrid, dygrid, skyrad_o,skyrad_i,mask_sky_contam,mosaic):\n",
    "\n",
    "    coords = wcsAD.all_world2pix(wcsFLT.all_pix2world(np.array([[x,y]],dtype=np.float_),0),0) \n",
    "    dx = coords[0,0]\n",
    "    dy = coords[0,1]\n",
    "    \n",
    "    dst = np.sqrt((dxgrid-dx)**2 + (dygrid-dy)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i) & mask_sky_contam \n",
    "    skyarr = mosaic[1].data[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr[np.isfinite(skyarr)],1.75,1.75)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n",
    "# Similar but for getting background values from the same image\n",
    "\n",
    "def getlocalbackground (x, y, xgrid, ygrid, skyrad_o,skyrad_i, image):\n",
    "\n",
    "    dst = np.sqrt((xgrid-x)**2 + (ygrid-y)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i)\n",
    "    skyarr = image[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr[np.isfinite(skyarr)],1.75,1.75)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n",
    "#msky = np.median(sigmaclip(meancurr_ima,1.75,1.75)[0])\n",
    "#def get_dark_rate(x, y, istim, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sky_and_indices(nz0, nz1, j, istim):\n",
    "    # Function to get the sky value, as well as calculate the indices needed in the large data cube of IMA reads\n",
    "       \n",
    "    #Get the sky from the drizzled image\n",
    "    imtyp = imtyps[istim+j]\n",
    "\n",
    "    if(imtyp == 'EXT'):\n",
    "#        skyhere = getskyfrommosaic(w_mosaic, w_vsflts[istim+j], nz1, nz0, dxgrid, dygrid, skyrad_o,skyrad_i,mask_sky_contam,mosaic)\n",
    "        skyhere = getlocalbackground(nz1, nz0, xgrid, ygrid, skyrad_o,skyrad_i, flts[istim+j,:,:])\n",
    "    elif(imtyp == 'DARK'):\n",
    "        skyhere = 0.0 #Do not subtract any sky, as the superdark is subtracted from IMA already\n",
    "    else:\n",
    "        print('Wrong image type')\n",
    "        assert False\n",
    "    \n",
    "    offset = ( tstrMJDs[istim+j] - tendMJDs[istim] )*daytosec\n",
    "    ioff = np.sum(nsamps[0:istim+j])\n",
    "    nsamp = nsamps[istim+j]\n",
    "    \n",
    "    k_product = product([nz0], [nz1], [skyhere], [offset], [ioff], [nsamp], [j], range(nsamp-1))\n",
    "    return list(k_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pixel_values(inputs, istim, PAM=None):\n",
    "    # function to extract the values from the IMA cube and IMA metadata arrays\n",
    "    \n",
    "    nz1, nz0, skyhere, offset, ioff, nsamp, j, k = inputs\n",
    "    te = ima_times[ioff+k]\n",
    "    ts = ima_times[ioff+k+1]\n",
    "\n",
    "    tfromstim = te + offset\n",
    "    tdenom    = te - ts  \n",
    "    meancurr  = (ima_scis[ioff+k,nz1,nz0]*te - ima_scis[ioff+k+1,nz1,nz0]*ts)/tdenom\n",
    "    stdvcurr  = np.sqrt(np.sum(np.square([ima_errs[ioff+k,nz1,nz0]*te,ima_errs[ioff+k+1,nz1,nz0]*ts])))/tdenom\n",
    "\n",
    "    if np.isnan(meancurr) == True:\n",
    "        \n",
    "        print(te,ts,ima_scis[ioff+k,nz1,nz0],ima_scis[ioff+k+1,nz1,nz0],inputs)\n",
    "        assert False\n",
    "    \n",
    "    if ((PAM is not None) & (imtyps[istim+j] == 'EXT')):\n",
    "#        meancurr = (meancurr-skyhere-MDRIZSKYs[istim+j]-ima_dsky[ioff+k])*pflats[pflats_names[istim+j]][nz1,nz0]\n",
    "#        meancurr = (meancurr-skyhere-ima_dsky[ioff+k])*pflats[pflats_names[istim+j]][nz1,nz0]\n",
    "#        meancurr  = (meancurr-skyhere+MDRIZSKYs[istim+j]-ima_dsky[ioff+k])*pflats[pflats_names[istim+j]][nz1,nz0]\n",
    "#        meancurr = (meancurr-skyhere-flts_avg_sky[istim+j]+ima_avg_sky[ioff+k])*pflats[pflats_names[istim+j]][nz1,nz0]\n",
    "        meancurr = (meancurr-skyhere)*pflats[pflats_names[istim+j]][nz1,nz0]\n",
    "#        meancurr = (meancurr-skyhere-DRZ_avg_sky+ima_avg_sky[ioff+k])*pflats[pflats_names[istim+j]][nz1,nz0]\n",
    "        stdvcurr *= pflats[pflats_names[istim+j]][nz1,nz0]\n",
    "    \n",
    "    exptime = (tendMJDs[istim]-tstrMJDs[istim])*daytosec\n",
    "    return [flts[istim,nz1,nz0]*exptime,\n",
    "            exptime,\n",
    "            nz0,\n",
    "            nz1,\n",
    "            tfromstim,\n",
    "            tdenom,\n",
    "            nsamp-k-1,\n",
    "            nsamp,\n",
    "            meancurr,\n",
    "            stdvcurr,\n",
    "            istim,\n",
    "            istim+j,\n",
    "            imtyps[istim],\n",
    "            imtyps[istim+j],\n",
    "            flts_dqs[istim,nz1,nz0],\n",
    "            ima_dqs[ioff+k,nz1,nz0]\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "57247.89789127 57247.90197646 352.96041641850024 EXT icrr01y7q_flt.fits\n",
      "57247.9027409 57247.90682572 352.9284480493516 EXT icrr01y8q_flt.fits\n",
      "57247.90759053 57247.91167535 352.9284480493516 EXT icrr01yaq_flt.fits\n",
      "57247.91243979 57247.91652498 352.9604157898575 EXT icrr01ycq_flt.fits\n",
      "57247.91728942 57247.9213746 352.9595520347357 EXT icrr01yeq_flt.fits\n",
      "57247.92213905 57247.92622386 352.927583665587 EXT icrr01ygq_flt.fits\n",
      "57247.92698868 57247.93107349 352.927583665587 EXT icrr01yiq_flt.fits\n",
      "57247.93219683 57247.93913238 599.2315201554447 DARK icrr01ykq_flt.fits\n",
      "57247.93937275 57247.94345794 352.9604157898575 DARK icrr01ymq_flt.fits\n",
      "57247.94370164 57247.94778646 352.9284480493516 DARK icrr01yoq_flt.fits\n",
      "57247.94803016 57247.95211535 352.96041641850024 DARK icrr01yqq_flt.fits\n",
      "57247.95235905 57247.95644386 352.927583665587 DARK icrr01ysq_flt.fits\n",
      "57247.95668757 57247.96077275 352.9595520347357 DARK icrr01yuq_flt.fits\n",
      "57247.96125942 57247.96534423 352.927583665587 DARK icrr01ywq_flt.fits\n",
      "57247.96558794 57247.96967312 352.9595520347357 DARK icrr01yyq_flt.fits\n",
      "57247.96991683 57247.97400164 352.92758429422975 DARK icrr01z0q_flt.fits\n",
      "57247.97424535 57247.97833053 352.9595520347357 DARK icrr01z2q_flt.fits\n",
      "57247.97857423 57247.98265905 352.9284480493516 DARK icrr01z4q_flt.fits\n",
      "57247.98290275 57247.98698794 352.9604157898575 DARK icrr01z6q_flt.fits\n",
      "57247.98723164 57247.99131646 352.9284480493516 DARK icrr01z8q_flt.fits\n",
      "57247.99156016 57247.99564535 352.9604157898575 DARK icrr01zaq_flt.fits\n",
      "57247.99588905 57247.99997386 352.92758429422975 DARK icrr01zcq_flt.fits\n",
      "57248.00021757 57248.00430275 352.9595520347357 DARK icrr01zeq_flt.fits\n",
      "***************\n",
      "57250.55087757 57250.55665572 499.23215999733657 EXT icrr02ozq_flt.fits\n",
      "57250.55741683 57250.56319498 499.23215999733657 EXT icrr02p0q_flt.fits\n",
      "57250.56395609 57250.56973423 499.231295613572 EXT icrr02p2q_flt.fits\n",
      "57250.57049535 57250.57627349 499.231295613572 EXT icrr02p3q_flt.fits\n",
      "57250.57703498 57250.58281312 499.23129624221474 EXT icrr02p5q_flt.fits\n",
      "57250.58393312 57250.59086868 599.2323845392093 DARK icrr02p6q_flt.fits\n",
      "57250.59110905 57250.59519386 352.927583665587 DARK icrr02p8q_flt.fits\n",
      "57250.59543757 57250.59952275 352.9595520347357 DARK icrr02paq_flt.fits\n",
      "57250.59976646 57250.60385127 352.92758429422975 DARK icrr02pcq_flt.fits\n",
      "57250.60409498 57250.60818016 352.9595520347357 DARK icrr02peq_flt.fits\n",
      "57250.60842386 57250.61250868 352.9284480493516 DARK icrr02pgq_flt.fits\n",
      "57250.61275238 57250.61683757 352.9604157898575 DARK icrr02piq_flt.fits\n",
      "57250.61732423 57250.62140905 352.9284480493516 DARK icrr02pkq_flt.fits\n",
      "57250.62165275 57250.62573794 352.9604157898575 DARK icrr02pmq_flt.fits\n",
      "57250.62598164 57250.63006646 352.9284480493516 DARK icrr02poq_flt.fits\n",
      "57250.63031016 57250.63439535 352.96041641850024 DARK icrr02pqq_flt.fits\n",
      "57250.63463905 57250.63872386 352.92758429422975 DARK icrr02psq_flt.fits\n",
      "57250.63896757 57250.64305275 352.9595520347357 DARK icrr02puq_flt.fits\n",
      "57250.64329646 57250.64738127 352.927583665587 DARK icrr02pwq_flt.fits\n",
      "57250.64762498 57250.65171016 352.95955140609294 DARK icrr02pyq_flt.fits\n",
      "57250.65195386 57250.65603868 352.9284480493516 DARK icrr02q0q_flt.fits\n",
      "***************\n",
      "57261.4189446 57261.42819498 799.2328317370266 EXT icrr03rqq_flt.fits\n",
      "57261.42895609 57261.43820646 799.2319679819047 EXT icrr03rrq_flt.fits\n",
      "57261.43896757 57261.44821831 799.2639357224107 EXT icrr03rtq_flt.fits\n",
      "57261.44933794 57261.45627349 599.2315201554447 DARK icrr03ruq_flt.fits\n",
      "57261.45651386 57261.46059905 352.9604157898575 DARK icrr03rwq_flt.fits\n",
      "57261.46084275 57261.46492757 352.9284480493516 DARK icrr03ryq_flt.fits\n",
      "57261.46517127 57261.46925646 352.9604157898575 DARK icrr03s0q_flt.fits\n",
      "57261.46950016 57261.47358498 352.9284480493516 DARK icrr03s2q_flt.fits\n",
      "57261.47382868 57261.47791386 352.9595520347357 DARK icrr03s4q_flt.fits\n",
      "57261.47815757 57261.48224238 352.927583665587 DARK icrr03s6q_flt.fits\n",
      "57261.48272942 57261.48681423 352.927583665587 DARK icrr03s8q_flt.fits\n",
      "57261.48705794 57261.49114312 352.9595520347357 DARK icrr03saq_flt.fits\n",
      "57261.49138683 57261.49547164 352.92758429422975 DARK icrr03scq_flt.fits\n",
      "57261.49571535 57261.49980053 352.9595520347357 DARK icrr03seq_flt.fits\n",
      "57261.50004423 57261.50412905 352.9284480493516 DARK icrr03sgq_flt.fits\n",
      "57261.50437275 57261.50845794 352.9604157898575 DARK icrr03siq_flt.fits\n",
      "57261.50870164 57261.51278646 352.9284480493516 DARK icrr03skq_flt.fits\n",
      "57261.51303016 57261.51711535 352.9604157898575 DARK icrr03smq_flt.fits\n",
      "57261.51735905 57261.52144386 352.92758429422975 DARK icrr03soq_flt.fits\n"
     ]
    }
   ],
   "source": [
    "#Read files header, make sure they are sorted by EXPSTART\n",
    "#This now copies the files into the mosaic hi res directory, keeping visit structure\n",
    "\n",
    "sflts= []\n",
    "\n",
    "for vis in ['1','2','3']:\n",
    "    qldir = pdir+'/14016_data/Visit0'+vis+'/'\n",
    "    wdir = mdir+'/Visit0'+vis+'/'\n",
    "    if not os.path.isdir(wdir):\n",
    "        os.mkdir(wdir)\n",
    "    flts = glob.glob(qldir+'*_flt.fits')\n",
    "    print('***************')\n",
    "    starttimes = []\n",
    "    endtimes   = []\n",
    "    imagetypes = []\n",
    "    for flt in flts:\n",
    "        starttimes.append(fits.getheader(flt,0)['EXPSTART'])\n",
    "        endtimes.append(fits.getheader(flt,0)['EXPEND'])\n",
    "        imagetypes.append(fits.getheader(flt,0)['IMAGETYP'])\n",
    "        filename = os.path.split(flt)[-1]\n",
    "        if not os.path.exists(wdir+filename):\n",
    "            shutil.copy(flt, wdir)\n",
    "            shutil.copy(flt.replace('_flt','_ima'), wdir)\n",
    "            \n",
    "    flts = glob.glob(wdir+'*_flt.fits')    \n",
    "    ii = np.argsort(starttimes)\n",
    "    for jj in range(len(flts)):\n",
    "        print(starttimes[ii[jj]],endtimes[ii[jj]],(-starttimes[ii[jj]]+endtimes[ii[jj]])*daytosec,imagetypes[ii[jj]],flts[ii[jj]][-18:])\n",
    "\n",
    "    sflts.append([flts[i] for i in ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose which visit to work on\n",
    "\n",
    "visit_index = 0\n",
    "vsflts = sflts[visit_index]\n",
    "\n",
    "# If in a hurry, shorten the list for faster analysis\n",
    "\n",
    "vsflts = vsflts[0:len(vsflts)-11]\n",
    "\n",
    "#plot all exposures multiple times for visualization of the selected pixels\n",
    "\n",
    "sf=1.5\n",
    "fig = plt.figure(figsize=(sf*len(vsflts),sf*len(vsflts)))\n",
    "\n",
    "ax = []\n",
    "for i,flt in enumerate(vsflts):\n",
    "    im = fits.getdata(flt)\n",
    "    c, low, upp = sigmaclip(im[np.isfinite(im)], 1.75,1.75)\n",
    "    mn = np.nanmean(c)\n",
    "    print(flt,'clipped mean: ',mn, 'AD sky:')\n",
    "    j = -1\n",
    "    while j < i: \n",
    "        j+=1\n",
    "        ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1+i))\n",
    "        ax[-1].imshow(np.log10(im/mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "        ax[-1].set_title(flt[-18:-9],fontsize=6)\n",
    "        ax[-1].get_xaxis().set_ticks([])\n",
    "        ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "        \n",
    "# Read the mosaic file and plot it\n",
    "\n",
    "plt.tight_layout()\n",
    "mosaic = fits.open(mdir+'/F140W_Mosaic_WFC3_IR_drz.fits')\n",
    "\n",
    "ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1))\n",
    "\n",
    "pos1 = ax[-1].get_position() # get the original position \n",
    "pos2 = [pos1.x0, pos1.y0,  pos1.width * len(vsflts)/2., pos1.height * len(vsflts)/2.] \n",
    "ax[-1].set_position(pos2) # set a new position\n",
    "ax[-1].get_xaxis().set_ticks([])\n",
    "ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "c, low, upp = sigmaclip(mosaic[1].data[np.where(np.isfinite(mosaic[1].data))], 1.75,1.75)\n",
    "mn = np.mean(c)\n",
    "im = ax[-1].imshow(np.log10(mosaic[1].data/mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "ax[-1].set_title('Drizzled \\n mosaic',fontsize=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the wcs objects for the AD mosaic and flts \n",
    "# For the external flts use the wcs info in the AD 4th extension to update\n",
    "# A WCS object created from the QL flts. This is needed because the WCS header of the flts copyied from QL\n",
    "# may not have the up-to-date WCS that have been updated by TWREG/AD to prodcue the mosaic\n",
    "\n",
    "flt2mosaic = list(mosaic[4].data['FILENAME']) #List of ALL the flts that contribute to the AD mosaic\n",
    "w_mosaic = WCS(mosaic[1].header)\n",
    "\n",
    "w_vsflts = []\n",
    "for vsflt in vsflts:\n",
    "    if (fits.getheader(vsflt,0)['IMAGETYP'] != 'EXT'):\n",
    "        w_vsflts.append(WCS(fits.getheader(vsflt,1)))\n",
    "    elif (fits.getheader(vsflt,0)['IMAGETYP'] == 'EXT'):\n",
    "\n",
    "        try:\n",
    "            index_element = flt2mosaic.index(vsflt[-18:])\n",
    "            w = WCS(fits.getheader(vsflt,1))\n",
    "            \n",
    "            crval1, crval2 = mosaic[4].data['CRVAL1'][index_element],mosaic[4].data['CRVAL2'][index_element]\n",
    "            cd1_1, cd1_2   = mosaic[4].data['CD1_1'][index_element],mosaic[4].data['CD1_2'][index_element]\n",
    "            cd2_1, cd2_2   = mosaic[4].data['CD2_1'][index_element],mosaic[4].data['CD2_2'][index_element]\n",
    "            \n",
    "            w.wcs.crval = [crval1,crval2]\n",
    "            w.wcs.cd    = np.array([[cd1_1, cd1_2],[cd2_1,cd2_2]])\n",
    "            \n",
    "        except ValueError:\n",
    "            print('Flt not in the mosaic!')\n",
    "            assert False\n",
    "        \n",
    "        w_vsflts.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the pixel-area map\n",
    "\n",
    "PAM = fits.getdata(pdir+'/Pixel_based/ir_wfc3_map.fits')\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "fig.add_subplot(121)\n",
    "plt.imshow(PAM,clim=(0.95,1.04))\n",
    "plt.colorbar()\n",
    "\n",
    "#Get the flt files to de-flatten the processed IMAs\n",
    "\n",
    "def get_flat(ext_file):\n",
    "    flatfile = fits.getval(ext_file,'PFLTFILE').replace('iref$','/grp/hst/cdbs/iref/')\n",
    "    return flatfile\n",
    "\n",
    "pflats_names = []\n",
    "for flt in vsflts:\n",
    "    if fits.getheader(flt)['IMAGETYP'] == 'EXT':\n",
    "        pflats_names.append(get_flat(flt))\n",
    "    else:\n",
    "        pflats_names.append(None)\n",
    "        \n",
    "\n",
    "pflats_unique = []\n",
    "for i in pflats_names:\n",
    "    if i is not(None):\n",
    "        if i not in pflats_unique:\n",
    "            pflats_unique.append(i)\n",
    "\n",
    "pflats = {}           \n",
    "for f in pflats_unique:\n",
    "    pflats[f] = fits.open(f)[1].data[5:-5,5:-5]\n",
    "    \n",
    "\n",
    "fig.add_subplot(122)\n",
    "plt.imshow(pflats[pflats_names[0]],clim=(0.95,1.04))\n",
    "\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lowlim, bs = 0., 0.2\n",
    "\n",
    "DRZdt = mosaic[1].data\n",
    "DRZ_avg_sky = np.nanmean(sigmaclip(DRZdt[np.isfinite(DRZdt)],1.75,1.75)[0])\n",
    "#Dh,BDh = np.histogram(DRZdt[np.isfinite(DRZdt)],bins=np.arange(lowlim,30,bs))\n",
    "\n",
    "#print(DRZsky,lowlim+bs*np.argmax(Dh),np.max(Dh))\n",
    "#fig = plt.figure()\n",
    "#plt.plot(np.log(BDh[:-1]),Dh/np.sum(Dh),c='black')\n",
    "#ima_offset = 0\n",
    "\n",
    "#for k in range(14):\n",
    "#    IMAdt = (ima_scis[ima_offset+k]*ima_times[ima_offset+k] - ima_scis[ima_offset+k+1]*ima_times[ima_offset+k+1])/(ima_times[ima_offset+k] - ima_times[ima_offset+k+1])\n",
    "#    IMAsky = np.nanmedian(sigmaclip(IMAdt[np.isfinite(IMAdt)],1.75,1.75)[0])\n",
    "#    Ih,BIh = np.histogram(IMAdt[np.isfinite(IMAdt)],bins=np.arange(lowlim,30,bs))\n",
    "#    print(IMAsky,lowlim+bs*np.argmax(Ih),np.max(Ih))\n",
    "#    plt.plot(np.log(BIh[:-1]),Ih/np.sum(Ih))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the current AD mosaic, get the sky values offsets that need to be used in the flts\n",
    "\n",
    "flt2mosaic = list(mosaic[4].data['FILENAME']) #List of ALL the flts that contribute to the AD mosaic\n",
    "MDRIZSKYs = []\n",
    "\n",
    "for vsflt in vsflts:\n",
    "    try:\n",
    "        index_element = flt2mosaic.index(vsflt[-18:])\n",
    "        MDRIZSKYs.append(mosaic[4].data['MDRIZSKY'][index_element])\n",
    "    except ValueError:\n",
    "        MDRIZSKYs.append(0.)\n",
    "    print(vsflt,MDRIZSKYs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocess darks- determine corresponding superdark\n",
    "def update_dark(vsflt):\n",
    "    if 'N/A' in fits.getval(vsflt,'DARKFILE',ext=0):\n",
    "        fits.setval(vsflt,'DARKCORR',value='PERFORM',ext=0)\n",
    "        errors = bestrefs.BestrefsScript('BestrefsScript --update-bestrefs -s 1 -f ' + vsflt)()\n",
    "        \n",
    "def get_superdark_plane(darkfile, nsamp):\n",
    "    darkfile = darkfile.replace('iref$','/grp/hst/cdbs/iref/')\n",
    "    hdu = fits.open(darkfile)\n",
    "    planes = []\n",
    "    for k in range(nsamp):\n",
    "        samp = 16-nsamp+k+1\n",
    "        if (hdu[1].header['BUNIT'] == 'COUNTS/S'):\n",
    "            planes.append(hdu['SCI',samp].data)\n",
    "        else:\n",
    "            if samp != 16:\n",
    "                planes.append( (hdu['SCI',samp].data - hdu['SCI',16].data )/hdu['TIME',samp].header['PIXVALUE'])\n",
    "            else:\n",
    "                planes.append( 0.*(hdu['SCI',samp].data))\n",
    "            \n",
    "    hdu.close()\n",
    "    return planes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to match the image coordinates with the astropy convention,\n",
    "#the first coordinate in the following numpy array is the y, the second the x \n",
    "\n",
    "gn_im = np.ones([1014,1014])\n",
    "\n",
    "hd = fits.open(vsflts[0])\n",
    "\n",
    "gn_im[0:507,0:507] = hd[0].header['ATODGNA'] #2.252  #q1\n",
    "gn_im[507:,0:507]  = hd[0].header['ATODGNB'] #2.203  #q2\n",
    "gn_im[507:,507:]   = hd[0].header['ATODGNC'] #2.188  #q3\n",
    "gn_im[0:507,507:]  = hd[0].header['ATODGND'] #2.265  #q4\n",
    "\n",
    "print(fits.open(vsflts[8])[0].header['*TODGN*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numpy arrays containg the ima and flt data as well\n",
    "# as the arrays of metadata.\n",
    "# Also subtract the MDRIZSKY from the flt for a 1-to-1 comaprison with the AD mosaic\n",
    "# Also bring the darks into e/s\n",
    "\n",
    "\n",
    "ima_scis  = []\n",
    "ima_errs  = []\n",
    "ima_dqs   = []\n",
    "ima_times = [] \n",
    "ima_avg_sky  = []\n",
    "\n",
    "flts      = []\n",
    "flts_dqs  = []\n",
    "flts_avg_sky  = []\n",
    "\n",
    "\n",
    "tendMJDs  = []\n",
    "tstrMJDs  = []\n",
    "imtyps    = []\n",
    "nsamps    = []\n",
    "sampseqs  = []\n",
    "\n",
    "ima_offset = 0\n",
    "\n",
    "for vsflt,MDS in zip(vsflts,MDRIZSKYs):\n",
    "    print('Appending '+vsflt+' to the datacube')\n",
    "\n",
    "    ima = fits.open(vsflt.replace('_flt','_ima'))\n",
    "    nsamps.append(ima[0].header['NSAMP'])\n",
    "    sampseqs.append(ima[0].header['SAMP_SEQ'])\n",
    "\n",
    "    hdr = fits.getheader(vsflt)\n",
    "    if (hdr['IMAGETYP'] == 'DARK'):\n",
    "        update_dark(vsflt)\n",
    "        print(fits.getval(vsflt,'DARKFILE'))\n",
    "        superdark_planes = get_superdark_plane(fits.getval(vsflt,'DARKFILE'),nsamps[-1])\n",
    "    \n",
    "    flt = fits.open(vsflt)\n",
    "    \n",
    "    \n",
    "    if (flt[1].header['BUNIT'] == 'COUNTS/S'):\n",
    "        fdt = flt['SCI'].data*flt[0].header['CCDGAIN']\n",
    "    elif (flt[1].header['BUNIT'] == 'ELECTRONS/S'):\n",
    "        fdt = flt['SCI'].data\n",
    "    else:\n",
    "        print('BUNITS not supported')\n",
    "        assert False\n",
    "    \n",
    "    \n",
    "    for k in range(nsamps[-1]):\n",
    "        if (ima['SCI',k+1].header['BUNIT'] == 'COUNTS/S' and (hdr['IMAGETYP'] == 'DARK')):\n",
    "            dark_sub_ima = ima['SCI',k+1].data-superdark_planes[k]\n",
    "#            imas = dark_sub_ima[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "#            imae = ima['ERR',k+1].data[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "            imas = dark_sub_ima[5:-5,5:-5]*gn_im\n",
    "            imae = ima['ERR',k+1].data[5:-5,5:-5]*gn_im\n",
    "\n",
    "        elif (ima['SCI',k+1].header['BUNIT'] == 'COUNTS/S'):\n",
    "            imas = ima['SCI',k+1].data[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "            imae = ima['ERR',k+1].data[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "            \n",
    "        elif (ima['SCI',k+1].header['BUNIT'] == 'ELECTRONS/S'):\n",
    "            imas = ima['SCI',k+1].data[5:-5,5:-5]\n",
    "            imae = ima['ERR',k+1].data[5:-5,5:-5]\n",
    "        else:\n",
    "            print('BUNITS not supported')\n",
    "            assert False\n",
    "                \n",
    "        ima_scis.append(imas)\n",
    "        ima_errs.append(imae)\n",
    "        ima_dqs.append(ima['DQ',k+1].data[5:-5,5:-5])\n",
    "        ima_times.append(ima['TIME',k+1].header['PIXVALUE'])\n",
    "\n",
    "#Avergae sky computation\n",
    "    if (hdr['IMAGETYP'] == 'EXT'):\n",
    "        afs = np.nanmean(sigmaclip(fdt[np.isfinite(fdt)],1.75,1.75)[0])\n",
    "#        print('Avg flt sky:',afs)\n",
    "        flts_avg_sky.append(afs)\n",
    "    else:\n",
    "        flts_avg_sky.append(0.)\n",
    "    \n",
    "    \n",
    "    for k in range(nsamps[-1]):    \n",
    "        if (hdr['IMAGETYP'] == 'EXT'):\n",
    "            if k == (nsamps[-1] - 1):\n",
    "                ima_avg_sky.append(0.)\n",
    "            else:\n",
    "                meancurr_ima = (ima_scis[ima_offset+k]*ima_times[ima_offset+k] - ima_scis[ima_offset+k+1]*ima_times[ima_offset+k+1])/(ima_times[ima_offset+k] - ima_times[ima_offset+k+1])\n",
    "                ais = np.nanmean(sigmaclip(meancurr_ima[np.isfinite(meancurr_ima)],1.75,1.75)[0])\n",
    "                ima_avg_sky.append(ais)\n",
    "#                print('Avg ima sky:',ais)\n",
    "        else:\n",
    "            ima_avg_sky.append(0.)\n",
    "        \n",
    "    ima_offset += nsamps[-1]\n",
    "\n",
    "    tendMJDs.append(flt[0].header['EXPEND'])\n",
    "    tstrMJDs.append(flt[0].header['EXPSTART'])\n",
    "    imtyps.append(flt[0].header['IMAGETYP'])\n",
    "    flts.append(fdt)\n",
    "    flts_dqs.append(flt['DQ'].data)\n",
    "    \n",
    "    flt.close()\n",
    "    ima.close()\n",
    "    \n",
    "\n",
    "print('Done1')\n",
    "ima_scis  = np.asarray(ima_scis)\n",
    "print('Done2')\n",
    "ima_errs  = np.asarray(ima_errs)\n",
    "print('Done3')\n",
    "ima_times = np.asarray(ima_times)\n",
    "print('Done4')\n",
    "ima_dqs = np.asarray(ima_dqs)\n",
    "print('Done5')\n",
    "flts      = np.asarray(flts)\n",
    "print('Done6')\n",
    "flts_dqs = np.asarray(flts_dqs)\n",
    "print('Done7')\n",
    "flts_avg_sky =  np.asarray(flts_avg_sky)\n",
    "print('Done8')\n",
    "tendMJDs  = np.asarray(tendMJDs)\n",
    "print('Done9')\n",
    "tstrMJDs  = np.asarray(tstrMJDs)\n",
    "print('Done10')\n",
    "imtyps    = np.asarray(imtyps)\n",
    "print('Done11')\n",
    "nsamps    = np.asarray(nsamps)\n",
    "print('Done12')\n",
    "ima_avg_sky   = np.asarray(ima_avg_sky)\n",
    "print('Done13')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the stimuli e-/s level to identify the ramps\n",
    "\n",
    "lev_u = np.inf\n",
    "lev_d = 4e4\n",
    "\n",
    "# Define the pixel grid (to trasform indices in x,y positions)\n",
    "xgrid,ygrid = np.meshgrid( np.arange(fits.getdata(vsflts[0],1).shape[1]) ,np.arange(fits.getdata(vsflts[0],1).shape[0]))\n",
    "dxgrid,dygrid = np.meshgrid( np.arange(mosaic[1].data.shape[1]) ,np.arange(mosaic[1].data.shape[0]))\n",
    "\n",
    "drz_finite = np.isfinite(mosaic[1].data)\n",
    "\n",
    "msky_d = np.nanmean(sigmaclip(mosaic[1].data[drz_finite],1.75,1.75)[0])\n",
    "ssky_d = np.nanstd(sigmaclip(mosaic[1].data[drz_finite],2.5,2.5)[0])\n",
    "mask_sky_contam = (mosaic[1].data <msky_d+1*ssky_d) & (mosaic[1].data >msky_d-2*ssky_d) & drz_finite\n",
    "\n",
    "skyrad_o = 15\n",
    "skyrad_i = 4\n",
    "lookback = None\n",
    "psf = 0.2\n",
    "numcores = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#before running the big step perform garbage collection\n",
    "gc.collect()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "cols = ['Stim','EXPTIME_stim','xpix','ypix','tfromstim','deltat','Read index','NSAMP','meancurr','stdvcurr','Ind_stim','Ind_pers','Stim_type','Pers_type','DQ_stim','DQ_pers']\n",
    "\n",
    "mypool = Pool(numcores)\n",
    "\n",
    "# Parallelized version\n",
    "for istim,stim in enumerate(vsflts[:-1]):\n",
    "\n",
    "    print('**********************')\n",
    "    print('Doing: ',stim)\n",
    "\n",
    "    if imtyps[istim] == 'EXT':\n",
    "    \n",
    "        icount    = find_ramps(istim,flts,lev_u,lev_d,lb=lookback,PAM=PAM,psf=psf)\n",
    "    \n",
    "        nz     = np.nonzero(icount)    \n",
    "        nnexts = icount[nz]\n",
    "    \n",
    "        nlines = 0\n",
    "        for nnext in nnexts:\n",
    "            nlines = nlines+np.sum((nsamps-1)[istim+1:istim+1+nnext])\n",
    "\n",
    "        print('Number of entries: ',nlines)\n",
    "        modulus = np.trunc(nlines/10)\n",
    "    \n",
    "        if (nlines > 0) :\n",
    "            flt_big_index = []\n",
    "            for nz0,nz1,nnext in list(zip(nz[0],nz[1],nnexts)):\n",
    "                prod = product([nz0], [nz1], range(1,nnext+1,1),[istim])\n",
    "                flt_big_index += list(prod)\n",
    "    \n",
    "            derp = mypool.starmap(get_sky_and_indices, flt_big_index)\n",
    "            ima_big_index = []\n",
    "            for block in derp:\n",
    "                ima_big_index += block\n",
    "        \n",
    "            biglist = mypool.starmap(get_pixel_values,zip(ima_big_index, [istim]*nlines, [PAM]*nlines))\n",
    "            df = df.append(pd.DataFrame(biglist,columns=cols),ignore_index=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the dataframe to save only non-redundant info\n",
    "\n",
    "df2 = df.set_index(['xpix', 'ypix','Ind_stim','Stim','EXPTIME_stim','Stim_type','DQ_stim'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iuniq  = df2.index.unique()\n",
    "df2['Uniq_multiindex'] = np.empty(len(df2),dtype=np.int_)\n",
    "\n",
    "print('Number of points:',len(df))\n",
    "print('Number of unique ramps:',len(iuniq))\n",
    "\n",
    "for i,ind in enumerate(iuniq):\n",
    "    if (i%1000 == 0):\n",
    "        print(i)\n",
    "    df2.loc[ind,'Uniq_multiindex'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make sure that the data types are set to more space-efficient ones\n",
    "\n",
    "df2['Ind_pers'] = df2['Ind_pers'].astype(np.uint8)\n",
    "df2['Read index'] = df2['Read index'].astype(np.uint8)\n",
    "df2['NSAMP'] = df2['NSAMP'].astype(np.uint8)\n",
    "df2[['tfromstim','deltat','meancurr','stdvcurr']] = df2[['tfromstim','deltat','meancurr','stdvcurr']].astype(np.float32)\n",
    "df2['Uniq_multiindex'] = df2['Uniq_multiindex'].astype(np.uint32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe mapping the uniqe ramps indices\n",
    "df_lookup = df2[['Uniq_multiindex']].copy().drop_duplicates()\n",
    "df_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe with persistence values\n",
    "\n",
    "df_values=pd.DataFrame()\n",
    "df_values['tfromstim']       = df2['tfromstim'].values \n",
    "df_values['deltat']          = df2['deltat'].values \n",
    "df_values['Read index']      = df2['Read index'].values \n",
    "df_values['meancurr']        = df2['meancurr'].values \n",
    "df_values['stdvcurr']        = df2['stdvcurr'].values \n",
    "df_values['NSAMP']           = df2['NSAMP'].values \n",
    "df_values['Ind_pers']        = df2['Ind_pers'].values \n",
    "df_values['Pers_type']       = df2['Pers_type'].values \n",
    "df_values['DQ_pers']         = df2['DQ_pers'].values \n",
    "df_values['Uniq_multiindex'] = df2['Uniq_multiindex'].values \n",
    "\n",
    "df_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_values.to_hdf(sdir+'DF.h5', 'Visit'+'{:0>2}'.format(str(visit_index+1))+'_values', mode='a',format = 't')\n",
    "df_lookup.to_hdf(sdir+'DF.h5', 'Visit'+'{:0>2}'.format(str(visit_index+1))+'_lookup', mode='a',format = 't')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
