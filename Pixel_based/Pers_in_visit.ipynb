{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to study short term persistence from multiple exposures in a single visit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import glob, os, shutil, pickle, bz2, gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sigmaclip\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import gammaincc, gamma\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import histogram\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "from crds import bestrefs\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The project dir \n",
    "pdir = '/user/gennaro/Functional_work/WFC3_persistence/py_progs/short_term_persistence/'\n",
    "\n",
    "#The mosaic dir\n",
    "mdir = pdir+'/Mosaic_hi_res_folder/'\n",
    "\n",
    "#The dir to save/load the Persistence curves dataframes\n",
    "sdir = pdir+'/PD_dataframes_dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion factor from days to seconds\n",
    "daytosec = 24.*3600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Single and double exponential models to be fitted to the data\n",
    "\n",
    "def decay1(t,a1,t1):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1\n",
    "\n",
    "def intdec1(t,a1,t1):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td)\n",
    "    \n",
    "def decay2(t,a1,t1,a2,t2):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    e2 = a2*np.exp(-t/t2)\n",
    "    return e1+e2\n",
    "\n",
    "def intdec2(t,a1,t1,a2,t2):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k1,k2  = -a1*t1, - a2*t2\n",
    "    \n",
    "    return k1*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) + k2*(np.exp(-tu/t2)-np.exp(-td/t2))/(tu-td)\n",
    "\n",
    "#Single exponential models plus a constant\n",
    "\n",
    "def intdec1_plusconst(t,a1,t1,q):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) +q\n",
    "\n",
    "def dec1_plusconst(t,a1,t1,q):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1+q\n",
    "\n",
    "\n",
    "#Shifted power law model\n",
    "\n",
    "def shpwl(t,t0,A,index):\n",
    "    return A * ((t+t0)/1000)**index\n",
    "\n",
    "def intshpwl(t,t0,A,index):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "\n",
    "    if (index == -1.):\n",
    "        return A*np.log( (tu+t0)/(td+t0) )\n",
    "    else:\n",
    "        return A/(1+index) * ( ((tu+t0)/1000)**(1+index) - ((td+t0)/1000)**(1+index) )/(tu-td)\n",
    "    \n",
    "    \n",
    "#Schechter like model\n",
    "\n",
    "def schechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "    return phi*(x**alpha)*np.exp(-x)\n",
    "\n",
    "def intschechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "\n",
    "    tu = x[1:]\n",
    "    td = x[:-1]\n",
    "\n",
    "    g1 = gammaincc(alpha+1,td)\n",
    "    g2 = gammaincc(alpha+1,tu)\n",
    "    \n",
    "    diff = gamma(alpha+1)*(g1-g2)\n",
    "    \n",
    "    return phi*diff\n",
    "\n",
    "\n",
    "#Geometric median calculation function\n",
    "\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "\n",
    "def geometric_median(X, eps=1e-5):\n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1, D\n",
    "\n",
    "        y = y1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes the vsflts list, the current flt that is being used as stimulus\n",
    "# and looks for all the pixels with valid stimulus values AND that have valid ramps (i.e. no source, only sky)\n",
    "# in the following exposures AND that where not stimulated more than prior-stim-factor (psf)% of the current stimulus in \n",
    "# ANY past exposure up to a certain look back exposure (lb).\n",
    "# Mario: added the option of multiplying the stimulus by the Pixel Area Map\n",
    "\n",
    "def find_ramps(istim,flts,lev_u,lev_d,lb=None,PAM=None,psf=0.1):\n",
    "        \n",
    "    stimdata  = flts[istim,:,:]*(tendMJDs[istim]-tstrMJDs[istim])*daytosec\n",
    "    \n",
    "    if PAM is not None:\n",
    "        stimdata *= PAM\n",
    "    \n",
    "    istimgood = (stimdata > lev_d) & (stimdata < lev_u)  \n",
    "    print('Pixels with potentially right stimuli:',np.sum(istimgood) )\n",
    "\n",
    "    if lb is not None:\n",
    "        if (istim-lb)>0:\n",
    "            st = istim-lb\n",
    "        else:\n",
    "            st = 0\n",
    "    else:\n",
    "        st = 0\n",
    "    \n",
    "    for i in range(st,istim,1):\n",
    "        persdata = flts[i,:,:] * (tendMJDs[i]-tstrMJDs[i])*daytosec \n",
    "        if PAM is not None:\n",
    "            persdata *= PAM\n",
    "\n",
    "        if (imtyps[i] == 'EXT'):\n",
    "            istimgood = istimgood & (persdata < psf*stimdata) \n",
    "            \n",
    "    print('Pixels with really right stimuli:',np.sum(istimgood) )\n",
    "    \n",
    "    \n",
    "    icount    = np.zeros_like(stimdata,dtype=np.int_)\n",
    "    iprev     = istimgood\n",
    "    for i in range(istim+1,len(imtyps),1):\n",
    "    \n",
    "        persdata = flts[i,:,:] * (tendMJDs[i]-tstrMJDs[i])*daytosec\n",
    "        if PAM is not None:\n",
    "            persdata *= PAM\n",
    "    \n",
    "        if (imtyps[i] == 'EXT'):\n",
    "            msky = np.nanmean(sigmaclip(persdata,2.,2.)[0])\n",
    "            ssky = np.nanstd(sigmaclip(persdata,2.,2.)[0])\n",
    "            iskycurr = (persdata <msky+2*ssky) & (persdata >msky-2*ssky)    \n",
    "        elif (imtyps[i] == 'DARK'):\n",
    "            iskycurr = np.ones_like(persdata,dtype=np.bool_)\n",
    "        else:\n",
    "            print('Wrong image type')\n",
    "            assert False\n",
    "        \n",
    "        igood = istimgood & iskycurr & iprev\n",
    "        iprev = igood\n",
    "        icount[igood] += 1\n",
    "\n",
    "        print('Pixels with ramps extending for at least',i-istim,' exposures:', igood.sum())\n",
    "        \n",
    "        if (np.sum(igood) == 0):\n",
    "            break\n",
    "                 \n",
    "    return icount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dedfine a function to get the sky value in the cureent flt pixel, but measured form the AD mosaic\n",
    "\n",
    "def getskyfrommosaic(wcsAD, wcsFLT, x, y, dxgrid, dygrid, skyrad_o,skyrad_i,mask_sky_contam,mosaic):\n",
    "\n",
    "    coords = wcsAD.all_world2pix(wcsFLT.all_pix2world(np.array([[x,y]],dtype=np.float_),0),0) \n",
    "    dx = coords[0,0]\n",
    "    dy = coords[0,1]\n",
    "    \n",
    "    dst = np.sqrt((dxgrid-dx)**2 + (dygrid-dy)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i) & mask_sky_contam \n",
    "    skyarr = mosaic[1].data[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr,2.,2.)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n",
    "# Similar but for getting background values from the smae image\n",
    "\n",
    "def getlocalbackground (x, y, xgrid, ygrid, skyrad_o,skyrad_i, fltdata):\n",
    "\n",
    "    dst = np.sqrt((xgrid-x)**2 + (ygrid-y)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i)\n",
    "    skyarr = fltdata[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr,2.,2.)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n",
    "#def get_dark_rate(x, y, istim, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sky_and_indices(nz0, nz1, j, istim):\n",
    "    # Function to get the sky value, as well as calculate the indices needed in the large data cube of IMA reads\n",
    "       \n",
    "    #Get the sky from the drizzled image\n",
    "    imtyp = imtyps[istim+j]\n",
    "\n",
    "    if(imtyp == 'EXT'):\n",
    "        skyhere = getskyfrommosaic(w_mosaic, w_vsflts[istim+j], nz1, nz0, dxgrid, dygrid, skyrad_o,skyrad_i,mask_sky_contam,mosaic)\n",
    "#        skyhere = getlocalbackground(nz1, nz0, xgrid, ygrid, skyrad_o,skyrad_i, flts[istim+j,:,:])\n",
    "    elif(imtyp == 'DARK'):\n",
    "        skyhere = 0.0 #Do not subtract any sky, as superdark is subtracted from IMA already\n",
    "    else:\n",
    "        print('Wrong image type')\n",
    "        assert False\n",
    "    \n",
    "    offset = ( tstrMJDs[istim+j] - tendMJDs[istim])*daytosec\n",
    "    ioff = np.sum(nsamps[0:istim+j])\n",
    "    nsamp = nsamps[istim+j]\n",
    "    \n",
    "    k_product = product([nz0], [nz1], [skyhere], [offset], [ioff], [nsamp], [j], range(nsamp-1))\n",
    "    return list(k_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pixel_values(inputs, istim, PAM=None):\n",
    "    # function to extract the values from the IMA cube and IMA metadata arrays\n",
    "    \n",
    "    nz1, nz0, skyhere, offset, ioff, nsamp, j, k = inputs\n",
    "    te = ima_times[ioff+k]\n",
    "    ts = ima_times[ioff+k+1]\n",
    "\n",
    "    tfromstim = te + offset\n",
    "    tdenom    = te - ts  \n",
    "    meancurr  = (ima_scis[ioff+k,nz1,nz0]*te - ima_scis[ioff+k+1,nz1,nz0]*ts)/tdenom\n",
    "    stdvcurr  = np.sqrt(np.sum(np.square([ima_errs[ioff+k,nz1,nz0]*te,ima_errs[ioff+k+1,nz1,nz0]*ts])))/tdenom\n",
    "\n",
    "    if np.isnan(meancurr) == True:\n",
    "        \n",
    "        print(te,ts,ima_scis[ioff+k,nz1,nz0],ima_scis[ioff+k+1,nz1,nz0],inputs)\n",
    "        assert False\n",
    "    \n",
    "    if ((PAM is not None) & (imtyps[istim+j] == 'EXT')):\n",
    "        meancurr = (meancurr-skyhere)*PAM[nz1,nz0]\n",
    "        stdvcurr *= PAM[nz1,nz0]\n",
    "        \n",
    "    exptime = (tendMJDs[istim]-tstrMJDs[istim])*daytosec\n",
    "    return [flts[istim,nz1,nz0]*exptime,\n",
    "            exptime,\n",
    "            nz0,\n",
    "            nz1,\n",
    "            tfromstim,\n",
    "            tdenom,\n",
    "            nsamp-k-1,\n",
    "            nsamp,\n",
    "            meancurr,\n",
    "            stdvcurr,\n",
    "            istim,\n",
    "            istim+j,\n",
    "            imtyps[istim],\n",
    "            imtyps[istim+j],\n",
    "            flts_dqs[istim,nz1,nz0],\n",
    "            ima_dqs[ioff+k,nz1,nz0]\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read files header, make sure they are sorted by EXPSTART\n",
    "#This now copies the files into the mosaic hi res directory, keeping visit structure\n",
    "\n",
    "sflts= []\n",
    "\n",
    "for vis in ['1','2','3']:\n",
    "    qldir = pdir+'/14016_data/Visit0'+vis+'/'\n",
    "    wdir = mdir+'/Visit0'+vis+'/'\n",
    "    if not os.path.isdir(wdir):\n",
    "        os.mkdir(wdir)\n",
    "    flts = glob.glob(qldir+'*_flt.fits')\n",
    "    print('***************')\n",
    "    starttimes = []\n",
    "    endtimes   = []\n",
    "    imagetypes = []\n",
    "    for flt in flts:\n",
    "        starttimes.append(fits.getheader(flt,0)['EXPSTART'])\n",
    "        endtimes.append(fits.getheader(flt,0)['EXPEND'])\n",
    "        imagetypes.append(fits.getheader(flt,0)['IMAGETYP'])\n",
    "        filename = os.path.split(flt)[-1]\n",
    "        if not os.path.exists(wdir+filename):\n",
    "            shutil.copy(flt, wdir)\n",
    "            shutil.copy(flt.replace('_flt','_ima'), wdir)\n",
    "            \n",
    "    flts = glob.glob(wdir+'*_flt.fits')    \n",
    "    ii = np.argsort(starttimes)\n",
    "    for jj in range(len(flts)):\n",
    "        print(starttimes[ii[jj]],endtimes[ii[jj]],(-starttimes[ii[jj]]+endtimes[ii[jj]])*daytosec,imagetypes[ii[jj]],flts[ii[jj]][-18:])\n",
    "\n",
    "    sflts.append([flts[i] for i in ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose which visit to work on\n",
    "\n",
    "visit_index = 0\n",
    "vsflts = sflts[visit_index]\n",
    "\n",
    "# If in a hurry, shorten the list for faster analysis\n",
    "\n",
    "#vsflts = vsflts[0:7]\n",
    "\n",
    "#plot all exposures multiple times for visualization of the selected pixels\n",
    "\n",
    "sf=1.5\n",
    "fig = plt.figure(figsize=(sf*len(vsflts),sf*len(vsflts)))\n",
    "\n",
    "ax = []\n",
    "for i,flt in enumerate(vsflts):\n",
    "    im = fits.getdata(flt)\n",
    "    c, low, upp = sigmaclip(im, 2.,2.)\n",
    "    mn = np.mean(c)\n",
    "    print(flt,'clipped mean: ',mn, 'AD sky:')\n",
    "    j = -1\n",
    "    while j < i: \n",
    "        j+=1\n",
    "        ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1+i))\n",
    "        ax[-1].imshow(np.log10(im/mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "        ax[-1].set_title(flt[-18:-9],fontsize=6)\n",
    "        ax[-1].get_xaxis().set_ticks([])\n",
    "        ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "        \n",
    "# Read the mosaic file and plot it\n",
    "\n",
    "plt.tight_layout()\n",
    "mosaic = fits.open(mdir+'/F140W_Mosaic_WFC3_IR_drz.fits')\n",
    "\n",
    "ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1))\n",
    "\n",
    "pos1 = ax[-1].get_position() # get the original position \n",
    "pos2 = [pos1.x0, pos1.y0,  pos1.width * len(vsflts)/2., pos1.height * len(vsflts)/2.] \n",
    "ax[-1].set_position(pos2) # set a new position\n",
    "ax[-1].get_xaxis().set_ticks([])\n",
    "ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "c, low, upp = sigmaclip(mosaic[1].data[np.where(np.isfinite(mosaic[1].data))], 2.,2.)\n",
    "mn = np.mean(c)\n",
    "im = ax[-1].imshow(np.log10(mosaic[1].data/mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "ax[-1].set_title('Drizzled \\n mosaic',fontsize=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the wcs objects for the AD mosaic and flts \n",
    "# For the external flts use the wcs info in the AD 4th extension to update\n",
    "# A WCS object created from the QL flts. This is needed because the WCS header of the flts copyied from QL\n",
    "# may not have the up-to-date WCS that have been updated by TWREG/AD to prodcue the mosaic\n",
    "\n",
    "flt2mosaic = list(mosaic[4].data['FILENAME']) #List of ALL the flts that contribute to the AD mosaic\n",
    "w_mosaic = WCS(mosaic[1].header)\n",
    "\n",
    "w_vsflts = []\n",
    "for vsflt in vsflts:\n",
    "    if (fits.getheader(vsflt,0)['IMAGETYP'] != 'EXT'):\n",
    "        w_vsflts.append(WCS(fits.getheader(vsflt,1)))\n",
    "    elif (fits.getheader(vsflt,0)['IMAGETYP'] == 'EXT'):\n",
    "\n",
    "        try:\n",
    "            index_element = flt2mosaic.index(vsflt[-18:])\n",
    "            w = WCS(fits.getheader(vsflt,1))\n",
    "            \n",
    "            crval1, crval2 = mosaic[4].data['CRVAL1'][index_element],mosaic[4].data['CRVAL2'][index_element]\n",
    "            cd1_1, cd1_2   = mosaic[4].data['CD1_1'][index_element],mosaic[4].data['CD1_2'][index_element]\n",
    "            cd2_1, cd2_2   = mosaic[4].data['CD2_1'][index_element],mosaic[4].data['CD2_2'][index_element]\n",
    "            \n",
    "            w.wcs.crval = [crval1,crval2]\n",
    "            w.wcs.cd    = np.array([[cd1_1, cd1_2],[cd2_1,cd2_2]])\n",
    "            \n",
    "        except ValueError:\n",
    "            print('Flt not in the mosaic!')\n",
    "            assert False\n",
    "        \n",
    "        w_vsflts.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the pixel-area map\n",
    "\n",
    "PAM = fits.getdata(pdir+'/Pixel_based/ir_wfc3_map.fits')\n",
    "\n",
    "fig =plt.figure(figsize=(4,4))\n",
    "plt.imshow(PAM)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the current AD mosaic, get the sky values offsets that need to be used in the flts\n",
    "\n",
    "flt2mosaic = list(mosaic[4].data['FILENAME']) #List of ALL the flts that contribute to the AD mosaic\n",
    "MDRIZSKYs = []\n",
    "\n",
    "for vsflt in vsflts:\n",
    "    try:\n",
    "        index_element = flt2mosaic.index(vsflt[-18:])\n",
    "        MDRIZSKYs.append(mosaic[4].data['MDRIZSKY'][index_element])\n",
    "    except ValueError:\n",
    "        MDRIZSKYs.append(0.)\n",
    "    print(vsflt,MDRIZSKYs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocess darks- determine corresponding superdark\n",
    "def update_dark(vsflt):\n",
    "    if 'N/A' in fits.getval(vsflt,'DARKFILE',ext=0):\n",
    "        fits.setval(vsflt,'DARKCORR',value='PERFORM',ext=0)\n",
    "        errors = bestrefs.BestrefsScript('BestrefsScript --update-bestrefs -s 1 -f ' + vsflt)()\n",
    "        \n",
    "def get_superdark_plane(darkfile, nsamp):\n",
    "    darkfile = darkfile.replace('iref$','/grp/hst/cdbs/iref/')\n",
    "    hdu = fits.open(darkfile)\n",
    "    planes = []\n",
    "    for k in range(nsamp):\n",
    "        samp = 16-nsamp+k+1\n",
    "        if (hdu[1].header['BUNIT'] == 'COUNTS/S'):\n",
    "            planes.append(hdu['SCI',samp].data)\n",
    "        else:\n",
    "            if samp != 16:\n",
    "                planes.append( (hdu['SCI',samp].data - hdu['SCI',16].data )/hdu['TIME',samp].header['PIXVALUE'])\n",
    "            else:\n",
    "                planes.append( 0.*(hdu['SCI',samp].data))\n",
    "            \n",
    "    hdu.close()\n",
    "    return planes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numpy arrays containg the ima and flt data as well\n",
    "# as the arrays of metadata.\n",
    "# Also subtract the MDRIZSKY from the flt for a 1-to-1 comaprison with the AD mosaic\n",
    "# Also bring the darks into e/s\n",
    "\n",
    "\n",
    "ima_scis  = []\n",
    "ima_errs  = []\n",
    "ima_dqs   = []\n",
    "ima_times = [] \n",
    "flts      = []\n",
    "flts_dqs  = []\n",
    "tendMJDs  = []\n",
    "tstrMJDs  = []\n",
    "imtyps    = []\n",
    "nsamps    = []\n",
    "sampseqs  = []\n",
    "\n",
    "for vsflt,MDS in zip(vsflts,MDRIZSKYs):\n",
    "    print('Appending '+vsflt+' to the datacube')\n",
    "\n",
    "    ima = fits.open(vsflt.replace('_flt','_ima'))\n",
    "    nsamps.append(ima[0].header['NSAMP'])\n",
    "    sampseqs.append(ima[0].header['SAMP_SEQ'])\n",
    "\n",
    "    hdr = fits.getheader(vsflt)\n",
    "    if (hdr['IMAGETYP'] == 'DARK'):\n",
    "        update_dark(vsflt)\n",
    "        print(fits.getval(vsflt,'DARKFILE'))\n",
    "        superdark_planes = get_superdark_plane(fits.getval(vsflt,'DARKFILE'),nsamps[-1])\n",
    "    \n",
    "    flt = fits.open(vsflt)\n",
    "    \n",
    "    \n",
    "    if (flt[1].header['BUNIT'] == 'COUNTS/S'):\n",
    "        fdt = flt['SCI'].data*flt[0].header['CCDGAIN']\n",
    "    elif (flt[1].header['BUNIT'] == 'ELECTRONS/S'):\n",
    "        fdt = flt['SCI'].data\n",
    "    else:\n",
    "        print('BUNITS not supported')\n",
    "        assert False\n",
    "    \n",
    "    \n",
    "    for k in range(nsamps[-1]):\n",
    "        if (ima['SCI',k+1].header['BUNIT'] == 'COUNTS/S' and (hdr['IMAGETYP'] == 'DARK')):\n",
    "            dark_sub_ima = ima['SCI',k+1].data-superdark_planes[k]\n",
    "            imas = dark_sub_ima[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "            imae = ima['ERR',k+1].data[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "        elif (ima['SCI',k+1].header['BUNIT'] == 'COUNTS/S'):\n",
    "            imas = ima['SCI',k+1].data[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "            imae = ima['ERR',k+1].data[5:-5,5:-5]*ima[0].header['CCDGAIN']\n",
    "            \n",
    "        elif (ima['SCI',k+1].header['BUNIT'] == 'ELECTRONS/S'):\n",
    "            imas = ima['SCI',k+1].data[5:-5,5:-5]\n",
    "            imae = ima['ERR',k+1].data[5:-5,5:-5]\n",
    "        else:\n",
    "            print('BUNITS not supported')\n",
    "            assert False\n",
    "            \n",
    "        ima_scis.append(imas)\n",
    "        ima_errs.append(imae)\n",
    "        ima_dqs.append(ima['DQ',k+1].data[5:-5,5:-5])\n",
    "        ima_times.append(ima['TIME',k+1].header['PIXVALUE'])\n",
    "   \n",
    "    \n",
    "    tendMJDs.append(flt[0].header['EXPEND'])\n",
    "    tstrMJDs.append(flt[0].header['EXPSTART'])\n",
    "    imtyps.append(flt[0].header['IMAGETYP'])\n",
    "    flts.append(fdt - MDS)\n",
    "    flts_dqs.append(flt['DQ'].data)\n",
    "    \n",
    "    flt.close()\n",
    "    ima.close()\n",
    "    \n",
    "\n",
    "print('Done1')\n",
    "ima_scis  = np.asarray(ima_scis)\n",
    "print('Done2')\n",
    "ima_errs  = np.asarray(ima_errs)\n",
    "print('Done3')\n",
    "ima_times = np.asarray(ima_times)\n",
    "print('Done4')\n",
    "ima_dqs = np.asarray(ima_dqs)\n",
    "print('Done5')\n",
    "flts      = np.asarray(flts)\n",
    "print('Done6')\n",
    "flts_dqs = np.asarray(flts_dqs)\n",
    "print('Done7')\n",
    "tendMJDs  = np.asarray(tendMJDs)\n",
    "print('Done8')\n",
    "tstrMJDs  = np.asarray(tstrMJDs)\n",
    "print('Done9')\n",
    "imtyps    = np.asarray(imtyps)\n",
    "print('Done10')\n",
    "nsamps    = np.asarray(nsamps)\n",
    "print('Done11')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the stimuli e-/s level to identify the ramps\n",
    "\n",
    "lev_u = np.inf\n",
    "lev_d = 1e7\n",
    "\n",
    "# Define the pixel grid (to trasform indices in x,y positions)\n",
    "xgrid,ygrid = np.meshgrid( np.arange(fits.getdata(vsflts[0],1).shape[1]) ,np.arange(fits.getdata(vsflts[0],1).shape[0]))\n",
    "dxgrid,dygrid = np.meshgrid( np.arange(mosaic[1].data.shape[1]) ,np.arange(mosaic[1].data.shape[0]))\n",
    "\n",
    "drz_fin = np.isfinite(mosaic[1].data)\n",
    "\n",
    "msky_d = np.nanmean(sigmaclip(mosaic[1].data[drz_fin],2.,2.)[0])\n",
    "ssky_d = np.nanstd(sigmaclip(mosaic[1].data[drz_fin],2.,2.)[0])\n",
    "mask_sky_contam = (mosaic[1].data <msky_d+3*ssky_d) & (mosaic[1].data >msky_d-3*ssky_d) & drz_fin\n",
    "\n",
    "skyrad_o = 12\n",
    "skyrad_i = 3\n",
    "lookback = None\n",
    "psf = 0.2\n",
    "numcores = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#before running the big step perform garbage collection\n",
    "gc.collect()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "cols = ['Stim','EXPTIME_stim','xpix','ypix','tfromstim','deltat','Read index','NSAMP','meancurr','stdvcurr','Ind_stim','Ind_pers','Stim_type','Pers_type','DQ_stim','DQ_pers']\n",
    "\n",
    "mypool = Pool(numcores)\n",
    "\n",
    "# Parallelized version\n",
    "for istim,stim in enumerate(vsflts[:-1]):\n",
    "\n",
    "    print('**********************')\n",
    "    print('Doing: ',stim)\n",
    "\n",
    "    if imtyps[istim] == 'EXT':\n",
    "    \n",
    "        icount    = find_ramps(istim,flts,lev_u,lev_d,lb=lookback,PAM=PAM,psf=psf)\n",
    "    \n",
    "        nz     = np.nonzero(icount)    \n",
    "        nnexts = icount[nz]\n",
    "    \n",
    "        nlines = 0\n",
    "        for nnext in nnexts:\n",
    "            nlines = nlines+np.sum((nsamps-1)[istim+1:istim+1+nnext])\n",
    "\n",
    "        print('Number of entries: ',nlines)\n",
    "        modulus = np.trunc(nlines/10)\n",
    "    \n",
    "        if (nlines > 0) :\n",
    "            flt_big_index = []\n",
    "            for nz0,nz1,nnext in list(zip(nz[0],nz[1],nnexts)):\n",
    "                prod = product([nz0], [nz1], range(1,nnext+1,1),[istim])\n",
    "                flt_big_index += list(prod)\n",
    "    \n",
    "            derp = mypool.starmap(get_sky_and_indices, flt_big_index)\n",
    "            ima_big_index = []\n",
    "            for block in derp:\n",
    "                ima_big_index += block\n",
    "        \n",
    "            biglist = mypool.starmap(get_pixel_values,zip(ima_big_index, [istim]*nlines, [PAM]*nlines))\n",
    "            df = df.append(pd.DataFrame(biglist,columns=cols),ignore_index=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the dataframe to save only non-redundant info\n",
    "\n",
    "df2 = df.set_index(['xpix', 'ypix','Ind_stim','Stim','EXPTIME_stim','Stim_type','DQ_stim'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iuniq  = df2.index.unique()\n",
    "df2['Uniq_multiindex'] = np.empty(len(df2),dtype=np.int_)\n",
    "\n",
    "print('Number of points:',len(df))\n",
    "print('Number of unique ramps:',len(iuniq))\n",
    "\n",
    "for i,ind in enumerate(iuniq):\n",
    "    if (i%500 == 0):\n",
    "        print(i)\n",
    "    df2.loc[ind,'Uniq_multiindex'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make sure that the data types are set to more space-efficient ones\n",
    "\n",
    "df2['Ind_pers'] = df2['Ind_pers'].astype(np.uint8)\n",
    "df2['Read index'] = df2['Read index'].astype(np.uint8)\n",
    "df2['NSAMP'] = df2['NSAMP'].astype(np.uint8)\n",
    "df2[['tfromstim','deltat','meancurr','stdvcurr']] = df2[['tfromstim','deltat','meancurr','stdvcurr']].astype(np.float32)\n",
    "df2['Uniq_multiindex'] = df2['Uniq_multiindex'].astype(np.uint32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe mapping the uniqe ramps indices\n",
    "df_lookup = df2[['Uniq_multiindex']].copy().drop_duplicates()\n",
    "df_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe with persistence values\n",
    "\n",
    "df_values=pd.DataFrame()\n",
    "df_values['tfromstim']       = df2['tfromstim'].values \n",
    "df_values['deltat']          = df2['deltat'].values \n",
    "df_values['Read index']      = df2['Read index'].values \n",
    "df_values['meancurr']        = df2['meancurr'].values \n",
    "df_values['stdvcurr']        = df2['stdvcurr'].values \n",
    "df_values['NSAMP']           = df2['NSAMP'].values \n",
    "df_values['Ind_pers']        = df2['Ind_pers'].values \n",
    "df_values['Pers_type']       = df2['Pers_type'].values \n",
    "df_values['DQ_pers']         = df2['DQ_pers'].values \n",
    "df_values['Uniq_multiindex'] = df2['Uniq_multiindex'].values \n",
    "\n",
    "df_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_values.to_hdf(sdir+'DF.h5', 'Visit'+'{:0>2}'.format(str(visit_index+1))+'_values', mode='a',format = 't')\n",
    "df_lookup.to_hdf(sdir+'DF.h5', 'Visit'+'{:0>2}'.format(str(visit_index+1))+'_lookup', mode='a',format = 't')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
